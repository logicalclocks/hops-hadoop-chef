<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

  <property>
    <name>dfs.replication</name>
    <value><%= node.hops.num_replicas %></value>
    <description>Default block replication.
    The actual number of replications can be specified when the file is created.
    The default is used if replication is not specified in create time.
    </description>
  </property>

  <property>
    <name>dfs.namenode.rpc-address</name>
    <value><%= @firstNN %></value>
    <description>
      RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,
      the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1
      dfs.namenode.rpc-address.EXAMPLENAMESERVICE
      The value of this property will take the form of hdfs://nn-host1:rpc-port.
    </description>
  </property>


  <property>
    <name>dfs.client.max.retries.on.failure</name>
    <value>1</value>
  </property>

  <property>
    <name>dfs.client.block.write.locateFollowingBlock.retries</name>
    <value>10</value>
  </property>

  <!-- Do not modify this file directly.  Instead, copy entries that you -->
  <!-- wish to modify from this file into hdfs-site.xml and change them -->
  <!-- there.  If hdfs-site.xml does not already exist, create it.      -->

  <!-- <property> -->
  <!--   <name>hadoop.hdfs.configuration.version</name> -->
  <!--   <value>1</value> -->
  <!--   <description>version of this configuration file</description> -->
  <!-- </property> -->

  <property>
    <name>dfs.namenode.accesstime.precision</name>
    <value>3600000</value>
    <description>The access time for HDFS file is precise upto this value. 
    The default value is 1 hour. Setting a value of 0 disables
    access times for HDFS.
    </description>
  </property>


  <property>
    <name>dfs.namenode.handler.count</name>
    <value>120</value>
    <description>The RPC server that listens to requests from clients</description>
  </property>

  <!-- <property> -->
  <!--    <name>dfs.namenode.service.handler.count</name> -->
  <!--   <value>10</value> -->
  <!--   <description>The RPC server threads that listens to requests from DataNodes</description> -->
  <!-- </property> -->

  <!-- <property> -->
  <!--   <name>dfs.datanode.data.dir</name> -->
  <!--   <value>file://<%= node.hops.dn.data_dir %></value> -->
  <!--   <description>Determines where on the local filesystem an DFS data node should store its blocks.  If this is a comma-delimited -->
  <!--   list of directories, then data will be storned in all named  directories, typically on different devices. Directories that do not exist are ignored. -->
  <!--   </description> -->
  <!-- </property> -->

  <property>
    <name>dfs.namenode.inodeid.batchsize</name>
    <value>100000</value>
    <description></description>
  </property>

  <property>
    <name>dfs.namenode.blockid.batchsize</name>
    <value>100000</value>
    <description></description>
  </property>

  <property>
    <name>dfs.blocksize</name>
    <value><%= node.hops.hdfs.blocksize %></value>
    <description>
        The default block size for new files, in bytes.
        You can use the following suffix (case insensitive):
        k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa) to specify the size (such as 128k, 512m, 1g, etc.),
        Or provide complete size in bytes (such as 134217728 for 128 MB).
    </description>
  </property>

  <property>
    <name>dfs.client.refresh.namenode.list</name>
    <value>60000</value>
    <description>Time in ms</description>
  </property>


  <property>
    <name>dfs.namenode.name.dir</name>
    <value><%= node.hops.nn.name_dir %></value>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value><%= node.hops.dn.data_dir %></value>
  </property>


  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>30000</value>
    <description>
      Determines extension of safe mode in milliseconds
      after the threshold level is reached.
    </description>
  </property>

  <property>
    <name>dfs.namenode.processReport.batchsize</name>
    <value>10000</value>
    <description>This is the number of blocks to be processed in one transaction.
    Higher values can result in higher throughput, but too high values can cause transactions to fail.
    </description>
  </property>

  <property>
    <name>dfs.namenode.misreplicated.batchsize</name>
    <value>500</value>
    <description>
      
    </description>
  </property>

  <property>
    <name>dfs.namenode.misreplicated.noofbatches</name>
    <value>10</value>
    <description>
    </description>
  </property>

  <!-- <property> -->
  <!--   <name>dfs.namenode.logging.level</name> -->
  <!--   <value><%= node.hops.log_level %></value> -->
  <!--   <description> -->
  <!--     The logging level for dfs namenode. Other values are "dir" (trace -->
  <!--     namespace mutations), "block" (trace block under/over replications -->
  <!--     and block creations/deletions), or "all". -->
  <!--   </description> -->
  <!-- </property> -->


  <property>
    <name>dfs.namenode.selector-policy</name>
    <value>RANDOM_STICKY</value>
    <description>Used by clients. Possible values ROUND_ROBIN, RANDOM, RANDOM_STICKY</description>
  </property>


  <property>
    <name>dfs.resolvingcache.memcache.connectionpool.size</name>
    <value>10</value>
    <description>should be same size as rpc threaads</description>
  </property>

  <property>
    <name>dfs.resolvingcache.enabled</name>
    <value><%= node.hops.nn.cache %></value>
    <description></description>
  </property>

  <property>
    <name>dfs.resolvingcache.type</name>
    <value>InMemory</value>
    <description></description>
  </property>

  <property>
    <name>dfs.resolvingcache.inmemory.maxsize</name>
    <value>2000000</value>
    <description></description>
  </property>

  <property>
    <name>dfs.ndb.setpartitionkey.enabled</name>
    <value><%= node.hops.nn.partition_key %></value>
    <description></description>
  </property>

  <property>
    <name>dfs.ndb.setrandompartitionkey.enabled</name>
    <value>true</value>
    <description></description>
  </property>

  <property>
    <name>dfs.namenode.quota.enabled</name>
    <value>true</value>
    <description></description>
  </property>

  <property>
    <name>dfs.permissions.enabled</name>
    <value>true</value>
    <description></description>
  </property>

  <property>
    <name>dfs.ndc.enable</name>
    <value>false</value>
    <description></description>
  </property>

  <property>
    <name>dfs.transaction.stats.enabled</name>
    <value>false</value>
    <description></description>
  </property>

  <property>
    <name>dfs.transaction.stats.detailed.enabled</name>
    <value>false</value>
    <description></description>
  </property>

  <property>
    <name>dfs.transaction.stats.writerround</name>
    <value>30</value>
    <description></description>
  </property>

  <property>
    <name>dfs.transaction.stats.dir</name>
    <value>/tmp/hopsstats</value>
    <description></description>
  </property>

  <property>
    <name>dfs.heartbeat.interval</name>
    <value>3</value>
    <description></description>
  </property>

  <!-- Enable erasure coding to test all code paths -->

  <property>
    <name>dfs.erasure_coding.enabled</name>
    <value><%= node.hops.erasure_coding %></value>    
    <description>Enable erasure coding</description>
  </property>

  <property>
     <name>dfs.webhdfs.enabled</name>
     <value>true</value>
  </property>
  
<!--
  <property>
    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
    <value><%= node.hops.reverse_dns_lookup_supported %></value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value><%= node.hops.tmp_dir %>/dn_socket</value>
  </property>

-->

<!-- SSL -->
<property>
    <name>dfs.https.enable</name>
    <value><%= node.hops.dfs.https.enable %></value>
</property>
<property>
    <name>dfs.http.policy</name>
    <value><%= node.hops.dfs.http.policy %></value>
</property>
<property>
    <name>dfs.datanode.https.address</name>
    <value><%= node.hops.dfs.datanode.https.address %></value>
</property>
<property>
    <name>dfs.namenode.https-address</name>
    <value><%= node.hops.dfs.namenode.https-address %></value>
</property>

</configuration>