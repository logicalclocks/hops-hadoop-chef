<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

  <!-- In: conf/core-site.xml -->
  <property>
    <name>hadoop.tmp.dir</name>
    <value><%= node['hops']['tmp_dir'] %></value>
    <description>A base for other temporary directories.</description>
  </property>

  <!--
      <property>
      <name>io.file.buffer.size</name>
      <value><%= node['hops']['io_buffer_sz'] %></value>
      <description>Size of read/write buffer used in SequenceFiles.</description>
      </property>
  -->

  <property>
    <name>dfs.namenodes.rpc.addresses</name>
    <value><%= @nn_rpc_endpoint %></value>
    <description>HopsFS-specific list of comma-separated host:port pairs for NameNodes.</description>
  </property>

  <property>
    <name>ipc.client.connect.max.retries</name>
    <value><%= node['hops']['max_retries'] %></value>
    <description>If a HDFS client has a communication problem with a NameNode, retry the connection the number of times specified here.</description>
  </property>

  <property>
    <name>dfs.client.retry.policy.spec</name>
    <value><%= node['hops']['retry_policy_spec'] %></value>
    <description>Retry policy specification. For example "10000,6,60000,10" means retry 6 times with 10 sec delay and then retry 10 times with 1 min delay. </description>
  </property>

  <property>
    <name>dfs.client.retry.policy.enabled</name>
    <value><%= node['hops']['retry_policy_enabled'] %></value>
    <description>Enable retry upon connection failure</description>
  </property>

  <property>
    <name>dfs.storage.driver.configfile</name>
    <value>ndb.props</value>
    <description>
    </description>
  </property>

  <property>
    <name>hops.service-discovery.enabled</name>
    <value><%= @service_discovery_enabled %></value>
    <description>Flag to get address from Service Discovery instead of configuration file.</description>
  </property>

  <property>
    <name>hadoop.proxyuser.<%= node['hops']['hdfs']['user'] %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['hdfs']['user'] %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @hopsworksUser %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @hopsworksUser %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['yarn']['user'] %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['yarn']['user'] %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['yarnapp']['user'] %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['yarnapp']['user'] %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['rm']['user'] %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['rm']['user'] %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @livyUser %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @livyUser %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @hiveUser %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @hiveUser %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['mr']['user'] %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= node['hops']['mr']['user'] %>.groups</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @flinkUser %>.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.<%= @flinkUser %>.groups</name>
    <value>*</value>
  </property>


  <property>
    <name>dfs.leader.check.interval</name>
    <value>2000</value>
    <description>Interval between the NameNode or ResourceMgr running the leader election protocol. </description>
  </property>

  <property>
    <name>dfs.leader.missed.hb</name>
    <value>2</value>
    <description></description>
  </property>

  <property>
    <name>dfs.leader.tp.increment</name>
    <value>100</value>
    <description></description>
  </property>


  <!-- SSL -->
  <property>
    <name>hadoop.ssl.require.client.cert</name>
    <value>false</value>
  </property>
  <property>
    <name>hadoop.ssl.hostname.verifier</name>
    <value>DEFAULT</value>
    <description></description>
  </property>
  <property>
    <name>hadoop.ssl.keystores.factory.class</name>
    <value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
    <description></description>
  </property>
  <property>
    <name>hadoop.ssl.server.conf</name>
    <value>ssl-server.xml</value>
    <description></description>
  </property>
  <property>
    <name>hadoop.ssl.client.conf</name>
    <value>ssl-client.xml</value>
    <description></description>
  </property>


  <property>
    <name>fs.defaultFS</name>
    <value><%= @defaultFS %></value>
  </property>

  <property>
    <name>fs.defaultFS.alternativeScheme</name>
    <value>hopsfs</value>
  </property>

  <property>
    <name>fs.trash.interval</name>
    <value><%= node['hops']['trash']['interval'] %></value>
  </property>

  <property>
    <name>fs.trash.checkpoint.interval</name>
    <value><%= node['hops']['trash']['checkpoint']['interval'] %></value>
  </property>

  <property>
    <name>hadoop.security.groups.cache.secs</name>
    <value>1</value>
  </property>

  <property>
    <name>ipc.server.read.threadpool.size</name>
    <value><%= node['hops']['server']['threadpool'] %></value>
  </property>

  <!-- RPC TLS support -->
  <property>
    <name>ipc.server.ssl.enabled</name>
    <value><%= node['hops']['tls']['enabled'] %></value>
  </property>

  <property>
    <name>hadoop.ssl.hostname.verifier</name>
    <value><%= node['hops']['hadoop']['ssl']['hostname']['verifier'] %></value>
  </property>

  <property>
    <name>hadoop.rpc.socket.factory.class.default</name>
    <value><%= @rpcSocketFactory %></value>
  </property>

  <% if node['hops']['tls']['enabled'].casecmp?("true") or node['hops']['rmappsecurity']['jwt']['enabled'].casecmp?("true") -%>

  <property>
    <name>hops.tls.superuser-material-directory</name>
    <value><%= node['x509']['super-crypto']['dir'] %></value>
  </property>

  <property>
    <name>hops.hopsworks.host</name>
    <value><%= @hopsworks %></value>
  </property>

  <!-- Service JWT renewal configuration -->
  <property>
    <name>hops.jwt-manager.master-token-validity</name>
    <value><%= node['hops']['jwt-manager']['master-token-validity'] %></value>
  </property>

  <property>
    <name>hops.jwt-manager.service-renew-path</name>
    <value><%= node['hops']['jwt-manager']['renew-path'] %></value>
  </property>

  <property>
    <name>hops.jwt-manager.service-invalidate-path</name>
    <value><%= node['hops']['jwt-manager']['invalidate-path'] %></value>
  </property>

  <% end -%>

  <% if node['hops']['tls']['enabled'].eql? "true" -%>

  <property>
    <name>hadoop.ssl.enabled.protocols</name>
    <value><%= node['hops']['hadoop']['ssl']['enabled']['protocols'] %></value>
  </property>

  <!--
      Directory where users' certificates are materialized from
      Hopsworks. It is used by HopsSSLSocketFactory to setup the
      correct crypto material for non-superuser.
      Default: /srv/hops/domains/domain1/kafkacerts
  -->
  <property>
    <name>client.materialize.directory</name>
    <value><%= node['certs']['dir'] %>/transient</value>
  </property>

  <!-- TLS client configuration -->

  <property>
    <name>client.rpc.ssl.enabled.protocol</name>
    <value>TLSv1.2</value>
  </property>

  <property>
    <name>hadoop.http.static.user</name>
    <value><%= @hopsworksUser %></value>
  </property>

  <property>
    <name>hadoop.ssl.require.client.cert</name>
    <value>true</value>
  </property>

  <!-- CRL validation configuration -->
  <property>
    <name>hops.crl.validation.enabled</name>
    <value><%= node['hops']['tls']['crl_enabled'] %></value>
  </property>

  <property>
    <name>hops.crl.fetcher.class</name>
    <value><%= node['hops']['tls']['crl_fetcher_class'] %></value>
  </property>

  <property>
    <name>hops.crl.input.uri</name>
    <value><%= @hopsworks_crl_uri %></value>
  </property>

  <property>
    <name>hops.crl.output.file</name>
    <value><%= node['hops']['tls']['crl_output_file'] %></value>
  </property>

  <property>
    <name>hops.crl.fetcher.interval</name>
    <value><%= node['hops']['tls']['crl_fetcher_interval'] %></value>
  </property>
  <% end -%>

<% if node['hops']['topology'].eql? "true" -%>
  <property>
    <name>net.topology.script.file.name</name>
    <value><%=node['hops']['conf_dir']%>/get-topology.sh</value>
  </property>
<% end -%>

<% if !node['hops']['s3a']['sse_algorithm'].eql? "" -%>
  <property>
    <name>fs.s3a.server-side-encryption-algorithm</name>
    <value><%= node['hops']['s3a']['sse_algorithm'] %></value>
  </property>
<% end -%>

<% if !node['hops']['s3a']['sse_key'].eql? "" -%>
  <property>
    <name>fs.s3a.server-side-encryption.key</name>
    <value><%= node['hops']['s3a']['sse_key'] %></value>
  </property>
<% end -%>

<property>
  <name>fs.s3a.buffer.dir</name>
  <value>${java.io.tmpdir}/s3a</value>
  <description>A comma separated list of temporary directories use for storing blocks of data prior to their being uploaded to S3. When unset (by default), hadoop.tmp.dir is used</description>
</property>

<% if node['install']['cloud'].eql? "azure" -%>
  <property>
    <name>fs.adl.oauth2.access.token.provider.type</name>
    <value>RefreshToken</value>
  </property>

  <property>
    <name>fs.adl.oauth2.client.id</name>
    <value></value>
  </property>

  <property>
    <name>fs.adl.oauth2.refresh.token</name>
    <value></value>
  </property>

  <property>
    <name>fs.azure.skipUserGroupMetadataDuringInitialization</name>
    <value>true</value>
  </property>
<% end -%>

</configuration>
